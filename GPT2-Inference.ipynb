{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e702b018-d74b-4bec-9097-fad0802e7ec5",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db852cb5-4917-475e-9174-82c06c0e4338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeevan/anaconda3/envs/succi/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel,TrainingArguments, Trainer,GPT2Config\n",
    "from sklearn.metrics import average_precision_score,matthews_corrcoef,f1_score, precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b719dfc-009f-466a-aa73-c9b140b2dc0a",
   "metadata": {},
   "source": [
    "## Example Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0575d48c-856d-4b30-bfb1-49d1cc9fa4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define benchmark dataset using pandas\n",
    "sequence='MASKSVVVLLFLALIASSAIAQAPGPAPTRSPLPSPAQPPRTAAPTPSITPTPTPTPSATPTAAPVSPPAGSPLPSSASPPAPPTSLTPDGAPVAGPTGSTPVDNNNAATLAAGSLAGFVFVASLLL'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160bc965-ba96-45b4-995c-6f41d41ab2bd",
   "metadata": {},
   "source": [
    "## Subsequence breakdown (Data pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37711c0-3385-44ed-aa24-db30694dbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subsequences(sequence:str, chars:list, left=10, right=10):\n",
    "    subsequences = []\n",
    "    length = len(sequence)\n",
    "    # Iterate through the sequence to find the character\n",
    "    for i, c in enumerate(sequence):\n",
    "        if c in chars:\n",
    "            # Calculate the start and end indices for the subsequence\n",
    "            start = max(0, i - left)  # Ensure start is not less than 0\n",
    "            end = min(length, i + right + 1)  # Ensure end does not exceed the sequence length\n",
    "            \n",
    "            # Append the subsequence to the list\n",
    "            subsequences.append({'Seq':sequence[start:end],\n",
    "                                 'Pos':i+1,\n",
    "                                 'text':f'<startoftext>SEQUENCE:{sequence[start:end]}\\nLABEL:'\n",
    "                                 })\n",
    "    return subsequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec36407f-a562-4a2e-8943-ecf1673139d8",
   "metadata": {},
   "source": [
    "## Load model | Load tokenizer | Prediction API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e786627a-0be4-4c6d-a26c-43e89cbcdd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(mdl_pth):\n",
    "    model_config = GPT2Config.from_pretrained(mdl_pth)\n",
    "    model = GPT2LMHeadModel.from_pretrained(mdl_pth,config=model_config,ignore_mismatched_sizes=True)\n",
    "    return model.cpu().eval()\n",
    "\n",
    "def tokenize(sub_sequences,tokenizer):\n",
    "    sub_sequences=[x['text'] for x in sub_sequences]\n",
    "    encoded=tokenizer(sub_sequences,return_tensors='pt',padding='longest')\n",
    "    return encoded\n",
    "\n",
    "def inference(input_seq,tokenizer_pth,model_pth,chars:list):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_pth,padding_side='left')\n",
    "    model=load_model(model_pth)\n",
    "    sub_sequences=find_subsequences(input_seq,chars=chars)\n",
    "    inputs_encode=tokenize(sub_sequences=sub_sequences,tokenizer=tokenizer)\n",
    "    predicted=model.generate(inputs_encode['input_ids'],attention_mask=inputs_encode['attention_mask'],do_sample=False,top_k=50,max_new_tokens=2,top_p=0.15,temperature=0.1,num_return_sequences=0,pad_token_id=50259)\n",
    "    predicted_text=tokenizer.batch_decode(predicted,skip_special_tokens=True)\n",
    "    predicted_labels=[x.split('LABEL:')[-1] for x in predicted_text]\n",
    "    json_results={'Sequence':input_seq,\n",
    "                'Type':model_pth,\n",
    "                'Results':[]\n",
    "                }\n",
    "    for label,sub_seq in zip(predicted_labels,sub_sequences):\n",
    "        json_results['Results'].append({sub_seq['Pos']:label})\n",
    "    return json_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2fe370-adc2-41a1-88fd-ffc9ed12aa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sequence': 'MASKSVVVLLFLALIASSAIAQAPGPAPTRSPLPSPAQPPRTAAPTPSITPTPTPTPSATPTAAPVSPPAGSPLPSSASPPAPPTSLTPDGAPVAGPTGSTPVDNNNAATLAAGSLAGFVFVASLLL', 'Type': 'Hydroxylation (P) sample model/', 'Results': [{24: 'POSITIVE'}, {26: 'POSITIVE'}, {28: 'POSITIVE'}, {32: 'POSITIVE'}, {34: 'POSITIVE'}, {36: 'POSITIVE'}, {39: 'POSITIVE'}, {40: 'POSITIVE'}, {45: 'NEGATIVE'}, {47: 'NEGATIVE'}, {51: 'NEGATIVE'}, {53: 'NEGATIVE'}, {55: 'NEGATIVE'}, {57: 'NEGATIVE'}, {61: 'NEGATIVE'}, {65: 'NEGATIVE'}, {68: 'NEGATIVE'}, {69: 'NEGATIVE'}, {73: 'NEGATIVE'}, {75: 'NEGATIVE'}, {80: 'NEGATIVE'}, {81: 'NEGATIVE'}, {83: 'NEGATIVE'}, {84: 'NEGATIVE'}, {89: 'NEGATIVE'}, {93: 'NEGATIVE'}, {97: 'NEGATIVE'}, {102: 'NEGATIVE'}]}\n"
     ]
    }
   ],
   "source": [
    "result = inference(sequence, 'Tokenizer/','Hydroxylation (P) sample model/',['P'])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
