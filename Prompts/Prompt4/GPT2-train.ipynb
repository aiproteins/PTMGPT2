{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db852cb5-4917-475e-9174-82c06c0e4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from transformers import DataCollatorWithPadding,DataCollatorForSeq2Seq\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel,TrainingArguments, Trainer,GPT2Config,EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11530999-cd73-4e08-b251-5cbf45b4ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use GPU else specify '-1' for CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b00c504-febc-4a5b-85b6-12f53a8afcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training data\n",
    "data=pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03612da8-7bae-400e-a94d-851481a8aff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRPVAVETALLYRTITTGEQGRGRSSVYSCPQDPLGAIYSRDALSK...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FKAGAERKEAAESTLVAYKSASDIATAELAPTHPIRLGLALNFSVF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEAGDDIKEAPKEVQKVDEQAQPPPSQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DMQDDVADDIKEAAPAAAKPADEQQS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSGNGGWDNWDNDDSFRSTDMRRNQSAGDFRSSGGRGAPAKSKSSE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253119</th>\n",
       "      <td>NSKNTVEMQSILHNTVLLFMICFEVYMLSVVWRAFVYICDFNMQRQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253120</th>\n",
       "      <td>DFNMQRQIEKIVQKKSMVKRSFDIEYDLVRNEIIRAEVKANEELV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253121</th>\n",
       "      <td>MNLLPYQFVGEVVRGFGRGGKELGCPTANMD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253122</th>\n",
       "      <td>ELGCPTANMDGTVVNGLPEGLPVGVYFGTAKLDGKSYKMAMSIGWN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253123</th>\n",
       "      <td>KMAMSIGWNPQYQNEKKTVELHLIDYSGSDFYGKTLSAVIIGFIRE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253124 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Seq  Label\n",
       "0       SRPVAVETALLYRTITTGEQGRGRSSVYSCPQDPLGAIYSRDALSK...      1\n",
       "1       FKAGAERKEAAESTLVAYKSASDIATAELAPTHPIRLGLALNFSVF...      1\n",
       "2                             DEAGDDIKEAPKEVQKVDEQAQPPPSQ      1\n",
       "3                              DMQDDVADDIKEAAPAAAKPADEQQS      1\n",
       "4       DSGNGGWDNWDNDDSFRSTDMRRNQSAGDFRSSGGRGAPAKSKSSE...      1\n",
       "...                                                   ...    ...\n",
       "253119  NSKNTVEMQSILHNTVLLFMICFEVYMLSVVWRAFVYICDFNMQRQ...      0\n",
       "253120      DFNMQRQIEKIVQKKSMVKRSFDIEYDLVRNEIIRAEVKANEELV      0\n",
       "253121                    MNLLPYQFVGEVVRGFGRGGKELGCPTANMD      0\n",
       "253122  ELGCPTANMDGTVVNGLPEGLPVGVYFGTAKLDGKSYKMAMSIGWN...      0\n",
       "253123  KMAMSIGWNPQYQNEKKTVELHLIDYSGSDFYGKTLSAVIIGFIRE...      0\n",
       "\n",
       "[253124 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcb79e5-f504-43be-9cdd-75a1bb9f07c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    138488\n",
       "1    114636\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the positive and negative labels\n",
    "data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32494e71-943e-4dcb-9c18-c6b8b61adf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove \\n and - characters from the sequence\n",
    "data['Seq']=data['Seq'].str.replace('-','')\n",
    "data['Seq']=data['Seq'].str.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ddc2ed-f76d-472f-9a33-7a22a309b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('nferruz/ProtGPT2',bos_token='<startoftext>',eos_token='<endoftext>',pad_token='<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f03bd472-bb93-44f6-81f5-830e8a9c7e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add custom tokens\n",
    "tokenizer.add_tokens(['POSITIVE','NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de038a1-673b-4c49-b21c-b0dd636f3db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<startoftext>',\n",
       " 'eos_token': '<endoftext>',\n",
       " 'unk_token': '<|endoftext|>',\n",
       " 'pad_token': '<PAD>'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f526869d-579a-43d4-9262-789ae4035983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map positive/negative labels and prepare prompt for training\n",
    "class SequenceClassificationDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, tokenizer,dtype='Train'):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.map_label={1:'POSITIVE',0:'NEGATIVE'}\n",
    "        self.dtype='Train'\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        prep_txt1= f'<startoftext>{sequence}\\n{self.map_label[label]}<endoftext>'\n",
    "        encoding1 = self.tokenizer(prep_txt1,return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding1['input_ids'].squeeze(), \n",
    "            'attention_mask': encoding1['attention_mask'].squeeze(), \n",
    "            'labels': encoding1['input_ids'].squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0575d48c-856d-4b30-bfb1-49d1cc9fa4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts=data['Seq'].reset_index(drop=True)\n",
    "train_labels=data['Label'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fed854e7-1e86-44c6-8522-14372e537a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=SequenceClassificationDataset(train_texts,train_labels,tokenizer,'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6f3b213-2ad4-4090-832e-1e254655613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pre-trained model\n",
    "model_config = GPT2Config.from_pretrained('nferruz/ProtGPT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d768994-5197-490d-a3d4-5b1669fedbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/media/8TB_hardisk/results-Prompt4/',  # output directory\n",
    "    num_train_epochs=200,  # total number of training epochs\n",
    "    per_device_train_batch_size=128,  # batch size per device during training\n",
    "    per_device_eval_batch_size=128,  # batch size for evaluation\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir='logs/',\n",
    "    save_steps=500,\n",
    "    logging_steps=500\n",
    "    save_total_limit=10 #no. of models to save in the output directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0df798b7-1c96-4e7b-ba97-f30cc346c112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50262, 1280)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('nferruz/ProtGPT2',config=model_config,ignore_mismatched_sizes=True)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a0bebae-de4c-4475-b2cf-2d5419f07de4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer,padding='longest')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cf890-5363-49ec-b5dc-3a68cfa3493c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
